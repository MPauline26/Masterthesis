\chapter{Conclusion}

In conclusion, this research has provided valuable insights into the comparative performance of the Random Forest algorithm and logistic regression model in predicting the Probability of Default. The results indicate that while the Random Forest model exhibits a slightly better predictive performance with a miniscule relative Gini improvement of 1,7\% on the test sample in discriminatory power and a marginal relative increase of 11,1\% in the F1 score for accuracy, it is crucial to consider the trade-offs. Notably, the Random Forest model shows a higher Type II error, suggesting an increased likelihood of false negatives compared to the logistic regression model.

Moreover, the exploration of interpretability through various methods, including feature importance, Partial Dependence Plots, Individual Component Explanation plots and plotting individual trees, has contributed to gaining more transparency into the decision-making processes of the models. However, the results of two individual scorings of the Random Forest model using LIME appear confusing and not intuitively interpretable. This underscores the persistent challenge of enhancing the transparency of machine learning models, particularly complex ensemble methods like Random Forest, and emphasizes the need for further research in developing more intuitive interpretability tools.

In light of these findings, the thesis contributes not only to the understanding of predictive advanced modeling in credit risk assessment but also highlights the ongoing challenges associated with interpretability in machine learning models. Future research should focus on refining and expanding interpretability methods to make the decision-making processes of advanced models more transparent and user-friendly, ensuring that the benefits of improved predictive performance are balanced with a clear understanding of model behavior and potential pitfalls.